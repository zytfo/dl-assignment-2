{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from functools import partial\n",
    "import time\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from sklearn.metrics import accuracy_score\n",
    "from DNNClassifier import DNNClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def shuffle_split(X, y, n_batches):\n",
    "    np.random.seed(seed=42)\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    for i_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch = X[i_idx]\n",
    "        y_batch = y[i_idx]\n",
    "        yield X_batch, y_batch\n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Build a DNN with five hidden layers of 100 neurons each, He initialization, and the ELU activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 start\n"
     ]
    }
   ],
   "source": [
    "print('Task 1 start')\n",
    "time.sleep(1)\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 100\n",
    "n_hidden2 = 100\n",
    "n_hidden3 = 100\n",
    "n_hidden4 = 100\n",
    "n_hidden5 = 100\n",
    "n_outputs = 5\n",
    "\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "dense_layer = partial(tf.layers.dense, activation=tf.nn.elu, kernel_initializer=he_init)\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name='X')\n",
    "y = tf.placeholder(tf.int64, shape=(None), name='y')\n",
    "\n",
    "with tf.name_scope('dnn'):\n",
    "    hidden1 = dense_layer(X, n_hidden1, name='hidden1')\n",
    "    hidden2 = dense_layer(hidden1, n_hidden2, name='hidden2')\n",
    "    hidden3 = dense_layer(hidden2, n_hidden3, name='hidden3')\n",
    "    hidden4 = dense_layer(hidden3, n_hidden4, name='hidden4')\n",
    "    hidden5 = dense_layer(hidden4, n_hidden5, name='hidden5')\n",
    "    logits = dense_layer(hidden5, n_outputs, activation=None, name='outputs')\n",
    "    \n",
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name='loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using Adam optimization and early stopping, try training it on MNIST but only on digits 0 to 4, as we will use transfer learning for digits 5 to 9 in the next exercise. You will need a softmax output layer with five neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2 start\n",
      "WARNING:tensorflow:From <ipython-input-3-432b8d914b3e>:13: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "0 train_acc: 1.0 test_acc: 0.9820977 loss 0.04894622\n",
      "1 train_acc: 0.98 test_acc: 0.98715705 loss 0.04120996\n",
      "2 train_acc: 1.0 test_acc: 0.98813 loss 0.03728239\n",
      "3 train_acc: 1.0 test_acc: 0.9910488 loss 0.030111544\n",
      "4 train_acc: 1.0 test_acc: 0.9918272 loss 0.026404124\n",
      "5 train_acc: 1.0 test_acc: 0.99065965 loss 0.0332601\n",
      "6 train_acc: 1.0 test_acc: 0.9918272 loss 0.030299986\n",
      "7 train_acc: 1.0 test_acc: 0.99143803 loss 0.02770311\n"
     ]
    }
   ],
   "source": [
    "print('Task 2 start')\n",
    "time.sleep(1)\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "mnist = input_data.read_data_sets('/tmp/data/')\n",
    "X_train = mnist.train.images[mnist.train.labels < 5]\n",
    "y_train = mnist.train.labels[mnist.train.labels < 5]\n",
    "X_test = mnist.test.images[mnist.test.labels < 5]\n",
    "y_test = mnist.test.labels[mnist.test.labels < 5]\n",
    "X_valid = mnist.validation.images[mnist.validation.labels < 5]\n",
    "y_valid = mnist.validation.labels[mnist.validation.labels < 5]\n",
    "\n",
    "\n",
    "n_epochs = 50\n",
    "batch_size = 50\n",
    "n_batches = len(X_train) // batch_size\n",
    "best_loss = float('inf')\n",
    "patience = 2\n",
    "cnt_patience = 0\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_split(X_train, y_train, n_batches):\n",
    "            sess.run([training_op, loss], feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "        loss_test = loss.eval(feed_dict={X: X_test, y: y_test})\n",
    "        print(epoch, 'train_acc:', accuracy_train, 'test_acc:', accuracy_test, 'loss', loss_test,)\n",
    "        if loss_test < best_loss:\n",
    "            best_loss = loss_test\n",
    "        else:\n",
    "            cnt_patience += 1\n",
    "            if cnt_patience > patience:\n",
    "                'Early stopping!'\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tune the hyperparameters using cross-validation and see what precision you can achieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 3 start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:643: DeprecationWarning: \"fit_params\" as a constructor argument was deprecated in version 0.19 and will be removed in version 0.21. Pass fit parameters to the \"fit\" method instead.\n",
      "  '\"fit\" method instead.', DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:271: UserWarning: The total space of parameters 2 is smaller than n_iter=50. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[CV] n_neurons=10, learning_rate=0.01, batch_size=10, activation=<function relu at 0x114093d08> \n",
      "0\tValidation loss: 0.163162\tBest loss: 0.163162\tAccuracy: 96.05%\n",
      "1\tValidation loss: 0.142110\tBest loss: 0.142110\tAccuracy: 95.86%\n",
      "2\tValidation loss: 0.151269\tBest loss: 0.142110\tAccuracy: 96.09%\n",
      "3\tValidation loss: 0.142484\tBest loss: 0.142110\tAccuracy: 96.21%\n",
      "4\tValidation loss: 0.128904\tBest loss: 0.128904\tAccuracy: 96.44%\n",
      "5\tValidation loss: 0.138315\tBest loss: 0.128904\tAccuracy: 95.97%\n",
      "6\tValidation loss: 0.140073\tBest loss: 0.128904\tAccuracy: 96.56%\n",
      "7\tValidation loss: 0.126383\tBest loss: 0.126383\tAccuracy: 96.79%\n",
      "8\tValidation loss: 0.145166\tBest loss: 0.126383\tAccuracy: 95.90%\n",
      "9\tValidation loss: 0.138134\tBest loss: 0.126383\tAccuracy: 96.56%\n",
      "[CV]  n_neurons=10, learning_rate=0.01, batch_size=10, activation=<function relu at 0x114093d08>, total=  22.7s\n",
      "[CV] n_neurons=10, learning_rate=0.01, batch_size=10, activation=<function relu at 0x114093d08> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   22.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.195183\tBest loss: 0.195183\tAccuracy: 94.57%\n",
      "1\tValidation loss: 0.133971\tBest loss: 0.133971\tAccuracy: 95.97%\n",
      "2\tValidation loss: 0.139042\tBest loss: 0.133971\tAccuracy: 96.09%\n",
      "3\tValidation loss: 0.099624\tBest loss: 0.099624\tAccuracy: 97.22%\n",
      "4\tValidation loss: 0.122260\tBest loss: 0.099624\tAccuracy: 96.72%\n",
      "5\tValidation loss: 0.119203\tBest loss: 0.099624\tAccuracy: 96.95%\n",
      "6\tValidation loss: 0.122047\tBest loss: 0.099624\tAccuracy: 96.72%\n",
      "7\tValidation loss: 0.115580\tBest loss: 0.099624\tAccuracy: 97.07%\n",
      "8\tValidation loss: 0.105392\tBest loss: 0.099624\tAccuracy: 97.19%\n",
      "9\tValidation loss: 0.112131\tBest loss: 0.099624\tAccuracy: 96.68%\n",
      "[CV]  n_neurons=10, learning_rate=0.01, batch_size=10, activation=<function relu at 0x114093d08>, total=  24.5s\n",
      "[CV] n_neurons=10, learning_rate=0.01, batch_size=10, activation=<function relu at 0x114093d08> \n",
      "0\tValidation loss: 0.186138\tBest loss: 0.186138\tAccuracy: 94.64%\n",
      "1\tValidation loss: 0.126624\tBest loss: 0.126624\tAccuracy: 96.76%\n",
      "2\tValidation loss: 0.174806\tBest loss: 0.126624\tAccuracy: 95.86%\n",
      "3\tValidation loss: 0.183067\tBest loss: 0.126624\tAccuracy: 94.96%\n",
      "4\tValidation loss: 0.170795\tBest loss: 0.126624\tAccuracy: 95.23%\n",
      "5\tValidation loss: 0.160171\tBest loss: 0.126624\tAccuracy: 96.17%\n",
      "6\tValidation loss: 0.152090\tBest loss: 0.126624\tAccuracy: 96.21%\n",
      "7\tValidation loss: 0.137738\tBest loss: 0.126624\tAccuracy: 96.44%\n",
      "8\tValidation loss: 0.162218\tBest loss: 0.126624\tAccuracy: 96.48%\n",
      "9\tValidation loss: 0.168371\tBest loss: 0.126624\tAccuracy: 96.40%\n",
      "[CV]  n_neurons=10, learning_rate=0.01, batch_size=10, activation=<function relu at 0x114093d08>, total=  19.8s\n",
      "[CV] n_neurons=10, learning_rate=0.01, batch_size=10, activation=<function elu at 0x11408c9d8> \n",
      "0\tValidation loss: 0.123217\tBest loss: 0.123217\tAccuracy: 96.87%\n",
      "1\tValidation loss: 0.110037\tBest loss: 0.110037\tAccuracy: 97.34%\n",
      "2\tValidation loss: 0.174504\tBest loss: 0.110037\tAccuracy: 95.82%\n",
      "3\tValidation loss: 0.109127\tBest loss: 0.109127\tAccuracy: 97.38%\n",
      "4\tValidation loss: 0.175740\tBest loss: 0.109127\tAccuracy: 95.78%\n",
      "5\tValidation loss: 0.107978\tBest loss: 0.107978\tAccuracy: 97.65%\n",
      "6\tValidation loss: 0.081887\tBest loss: 0.081887\tAccuracy: 97.85%\n",
      "7\tValidation loss: 0.092849\tBest loss: 0.081887\tAccuracy: 97.77%\n",
      "8\tValidation loss: 0.090711\tBest loss: 0.081887\tAccuracy: 97.89%\n",
      "9\tValidation loss: 0.091555\tBest loss: 0.081887\tAccuracy: 97.73%\n",
      "[CV]  n_neurons=10, learning_rate=0.01, batch_size=10, activation=<function elu at 0x11408c9d8>, total=  18.1s\n",
      "[CV] n_neurons=10, learning_rate=0.01, batch_size=10, activation=<function elu at 0x11408c9d8> \n",
      "0\tValidation loss: 0.160537\tBest loss: 0.160537\tAccuracy: 95.47%\n",
      "1\tValidation loss: 0.124009\tBest loss: 0.124009\tAccuracy: 96.60%\n",
      "2\tValidation loss: 0.127408\tBest loss: 0.124009\tAccuracy: 96.83%\n",
      "3\tValidation loss: 0.108697\tBest loss: 0.108697\tAccuracy: 97.50%\n",
      "4\tValidation loss: 0.104971\tBest loss: 0.104971\tAccuracy: 97.11%\n",
      "5\tValidation loss: 0.113250\tBest loss: 0.104971\tAccuracy: 96.68%\n",
      "6\tValidation loss: 0.098921\tBest loss: 0.098921\tAccuracy: 97.69%\n",
      "7\tValidation loss: 0.119264\tBest loss: 0.098921\tAccuracy: 96.95%\n",
      "8\tValidation loss: 0.097735\tBest loss: 0.097735\tAccuracy: 97.97%\n",
      "9\tValidation loss: 0.141011\tBest loss: 0.097735\tAccuracy: 97.26%\n",
      "[CV]  n_neurons=10, learning_rate=0.01, batch_size=10, activation=<function elu at 0x11408c9d8>, total=  17.7s\n",
      "[CV] n_neurons=10, learning_rate=0.01, batch_size=10, activation=<function elu at 0x11408c9d8> \n",
      "0\tValidation loss: 0.135081\tBest loss: 0.135081\tAccuracy: 96.83%\n",
      "1\tValidation loss: 0.098564\tBest loss: 0.098564\tAccuracy: 97.34%\n",
      "2\tValidation loss: 0.131321\tBest loss: 0.098564\tAccuracy: 96.72%\n",
      "3\tValidation loss: 0.097490\tBest loss: 0.097490\tAccuracy: 97.69%\n",
      "4\tValidation loss: 0.144970\tBest loss: 0.097490\tAccuracy: 96.60%\n",
      "5\tValidation loss: 0.096502\tBest loss: 0.096502\tAccuracy: 97.81%\n",
      "6\tValidation loss: 0.098584\tBest loss: 0.096502\tAccuracy: 97.69%\n",
      "7\tValidation loss: 0.103917\tBest loss: 0.096502\tAccuracy: 97.97%\n",
      "8\tValidation loss: 0.100184\tBest loss: 0.096502\tAccuracy: 97.93%\n",
      "9\tValidation loss: 0.099915\tBest loss: 0.096502\tAccuracy: 98.08%\n",
      "[CV]  n_neurons=10, learning_rate=0.01, batch_size=10, activation=<function elu at 0x11408c9d8>, total=  18.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.103769\tBest loss: 0.103769\tAccuracy: 96.95%\n",
      "1\tValidation loss: 0.097480\tBest loss: 0.097480\tAccuracy: 97.54%\n",
      "2\tValidation loss: 0.088346\tBest loss: 0.088346\tAccuracy: 97.73%\n",
      "3\tValidation loss: 0.085567\tBest loss: 0.085567\tAccuracy: 97.81%\n",
      "4\tValidation loss: 0.097083\tBest loss: 0.085567\tAccuracy: 97.38%\n",
      "5\tValidation loss: 0.095767\tBest loss: 0.085567\tAccuracy: 97.34%\n",
      "6\tValidation loss: 0.115644\tBest loss: 0.085567\tAccuracy: 97.38%\n",
      "7\tValidation loss: 0.104943\tBest loss: 0.085567\tAccuracy: 97.03%\n",
      "8\tValidation loss: 0.089925\tBest loss: 0.085567\tAccuracy: 97.89%\n",
      "9\tValidation loss: 0.085950\tBest loss: 0.085567\tAccuracy: 97.93%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9824868651488616"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Task 3 start')\n",
    "time.sleep(1)\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_neurons\": [10],\n",
    "    \"batch_size\": [10],\n",
    "    \"learning_rate\": [0.01],\n",
    "    \"activation\": [tf.nn.relu, tf.nn.elu],\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(DNNClassifier(random_state=42), param_distribs, n_iter=50,fit_params={\"X_valid\": X_valid, \"y_valid\": y_valid, \"n_epochs\": 10},\n",
    "                                random_state=42, verbose=2)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "y_pred = random_search.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Now try adding Batch Normalization and compare the learning curves: is it converging faster than before? Does it produce a better model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 4 start\n",
      "0\tValidation loss: 0.038478\tBest loss: 0.038478\tAccuracy: 98.87%\n",
      "1\tValidation loss: 0.036767\tBest loss: 0.036767\tAccuracy: 98.71%\n",
      "2\tValidation loss: 0.039822\tBest loss: 0.036767\tAccuracy: 98.83%\n",
      "3\tValidation loss: 0.036627\tBest loss: 0.036627\tAccuracy: 98.79%\n",
      "4\tValidation loss: 0.047019\tBest loss: 0.036627\tAccuracy: 98.63%\n",
      "5\tValidation loss: 0.031215\tBest loss: 0.031215\tAccuracy: 99.10%\n",
      "6\tValidation loss: 0.044797\tBest loss: 0.031215\tAccuracy: 98.55%\n",
      "7\tValidation loss: 0.028140\tBest loss: 0.028140\tAccuracy: 99.10%\n",
      "8\tValidation loss: 0.033399\tBest loss: 0.028140\tAccuracy: 98.98%\n",
      "9\tValidation loss: 0.033288\tBest loss: 0.028140\tAccuracy: 99.18%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x1c28931ae8>,\n",
       "       batch_norm_momentum=0.95, batch_size=500, dropout_rate=None,\n",
       "       initializer=<function variance_scaling_initializer.<locals>._initializer at 0xb24b059d8>,\n",
       "       learning_rate=0.01, n_hidden_layers=5, n_neurons=90,\n",
       "       optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>,\n",
       "       random_state=42)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Task 4 start')\n",
    "time.sleep(1)\n",
    "\n",
    "def leaky_relu(alpha=0.01):\n",
    "    def parametrized_leaky_relu(z, name=None):\n",
    "        return tf.maximum(alpha * z, z, name=name)\n",
    "    return parametrized_leaky_relu\n",
    "\n",
    "dnn_clf_bn = DNNClassifier(activation=leaky_relu(alpha=0.1), batch_size=500, learning_rate=0.01,n_neurons=90, random_state=42,\n",
    "                           batch_norm_momentum=0.95)\n",
    "dnn_clf_bn.fit(X_train, y_train, n_epochs=10, X_valid=X_valid, y_valid=y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It is converging faster, but overall accuracy is a bit worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Is the model overfitting the training set? Try adding dropout to every layer and try again. Does it help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[CV] n_neurons=10, learning_rate=0.01, dropout_rate=0.1, batch_size=10, batch_norm_momentum=0.9, activation=<function relu at 0x114093d08> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:643: DeprecationWarning: \"fit_params\" as a constructor argument was deprecated in version 0.19 and will be removed in version 0.21. Pass fit parameters to the \"fit\" method instead.\n",
      "  '\"fit\" method instead.', DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:271: UserWarning: The total space of parameters 2 is smaller than n_iter=50. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.204085\tBest loss: 0.204085\tAccuracy: 94.49%\n",
      "1\tValidation loss: 0.169103\tBest loss: 0.169103\tAccuracy: 94.80%\n",
      "2\tValidation loss: 0.175184\tBest loss: 0.169103\tAccuracy: 94.84%\n",
      "3\tValidation loss: 0.163380\tBest loss: 0.163380\tAccuracy: 95.27%\n",
      "4\tValidation loss: 0.164530\tBest loss: 0.163380\tAccuracy: 95.58%\n",
      "5\tValidation loss: 0.137814\tBest loss: 0.137814\tAccuracy: 96.29%\n",
      "6\tValidation loss: 0.173640\tBest loss: 0.137814\tAccuracy: 95.50%\n",
      "7\tValidation loss: 0.147342\tBest loss: 0.137814\tAccuracy: 95.93%\n",
      "8\tValidation loss: 0.140294\tBest loss: 0.137814\tAccuracy: 96.44%\n",
      "9\tValidation loss: 0.131124\tBest loss: 0.131124\tAccuracy: 96.76%\n",
      "[CV]  n_neurons=10, learning_rate=0.01, dropout_rate=0.1, batch_size=10, batch_norm_momentum=0.9, activation=<function relu at 0x114093d08>, total= 1.5min\n",
      "[CV] n_neurons=10, learning_rate=0.01, dropout_rate=0.1, batch_size=10, batch_norm_momentum=0.9, activation=<function relu at 0x114093d08> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.187497\tBest loss: 0.187497\tAccuracy: 94.64%\n",
      "1\tValidation loss: 0.175127\tBest loss: 0.175127\tAccuracy: 95.62%\n",
      "2\tValidation loss: 0.155351\tBest loss: 0.155351\tAccuracy: 95.90%\n",
      "3\tValidation loss: 0.148643\tBest loss: 0.148643\tAccuracy: 95.82%\n",
      "4\tValidation loss: 0.139371\tBest loss: 0.139371\tAccuracy: 96.29%\n",
      "5\tValidation loss: 0.156797\tBest loss: 0.139371\tAccuracy: 95.47%\n",
      "6\tValidation loss: 0.150020\tBest loss: 0.139371\tAccuracy: 96.64%\n",
      "7\tValidation loss: 0.147593\tBest loss: 0.139371\tAccuracy: 96.01%\n",
      "8\tValidation loss: 0.125479\tBest loss: 0.125479\tAccuracy: 96.36%\n",
      "9\tValidation loss: 0.127403\tBest loss: 0.125479\tAccuracy: 96.36%\n",
      "[CV]  n_neurons=10, learning_rate=0.01, dropout_rate=0.1, batch_size=10, batch_norm_momentum=0.9, activation=<function relu at 0x114093d08>, total= 1.6min\n",
      "[CV] n_neurons=10, learning_rate=0.01, dropout_rate=0.1, batch_size=10, batch_norm_momentum=0.9, activation=<function relu at 0x114093d08> \n",
      "0\tValidation loss: 0.207432\tBest loss: 0.207432\tAccuracy: 95.43%\n",
      "1\tValidation loss: 0.171039\tBest loss: 0.171039\tAccuracy: 95.74%\n",
      "2\tValidation loss: 0.176475\tBest loss: 0.171039\tAccuracy: 95.23%\n",
      "3\tValidation loss: 0.179012\tBest loss: 0.171039\tAccuracy: 94.88%\n",
      "4\tValidation loss: 0.153781\tBest loss: 0.153781\tAccuracy: 95.86%\n",
      "5\tValidation loss: 0.175501\tBest loss: 0.153781\tAccuracy: 94.92%\n",
      "6\tValidation loss: 0.146303\tBest loss: 0.146303\tAccuracy: 96.79%\n",
      "7\tValidation loss: 0.171499\tBest loss: 0.146303\tAccuracy: 95.50%\n",
      "8\tValidation loss: 0.122912\tBest loss: 0.122912\tAccuracy: 96.29%\n",
      "9\tValidation loss: 0.131560\tBest loss: 0.122912\tAccuracy: 96.95%\n",
      "[CV]  n_neurons=10, learning_rate=0.01, dropout_rate=0.1, batch_size=10, batch_norm_momentum=0.9, activation=<function relu at 0x114093d08>, total= 1.7min\n",
      "[CV] n_neurons=10, learning_rate=0.01, dropout_rate=0.1, batch_size=10, batch_norm_momentum=0.9, activation=<function elu at 0x11408c9d8> \n",
      "0\tValidation loss: 0.142291\tBest loss: 0.142291\tAccuracy: 95.62%\n",
      "1\tValidation loss: 0.132845\tBest loss: 0.132845\tAccuracy: 95.82%\n",
      "2\tValidation loss: 0.127614\tBest loss: 0.127614\tAccuracy: 95.78%\n",
      "3\tValidation loss: 0.134966\tBest loss: 0.127614\tAccuracy: 95.93%\n",
      "4\tValidation loss: 0.107086\tBest loss: 0.107086\tAccuracy: 96.72%\n",
      "5\tValidation loss: 0.104508\tBest loss: 0.104508\tAccuracy: 96.29%\n",
      "6\tValidation loss: 0.109155\tBest loss: 0.104508\tAccuracy: 96.60%\n",
      "7\tValidation loss: 0.093174\tBest loss: 0.093174\tAccuracy: 97.11%\n",
      "8\tValidation loss: 0.100120\tBest loss: 0.093174\tAccuracy: 96.99%\n",
      "9\tValidation loss: 0.097292\tBest loss: 0.093174\tAccuracy: 97.15%\n",
      "[CV]  n_neurons=10, learning_rate=0.01, dropout_rate=0.1, batch_size=10, batch_norm_momentum=0.9, activation=<function elu at 0x11408c9d8>, total= 1.5min\n",
      "[CV] n_neurons=10, learning_rate=0.01, dropout_rate=0.1, batch_size=10, batch_norm_momentum=0.9, activation=<function elu at 0x11408c9d8> \n",
      "0\tValidation loss: 0.156818\tBest loss: 0.156818\tAccuracy: 95.54%\n",
      "1\tValidation loss: 0.127689\tBest loss: 0.127689\tAccuracy: 96.09%\n",
      "2\tValidation loss: 0.129144\tBest loss: 0.127689\tAccuracy: 96.17%\n",
      "3\tValidation loss: 0.122975\tBest loss: 0.122975\tAccuracy: 96.25%\n",
      "4\tValidation loss: 0.112957\tBest loss: 0.112957\tAccuracy: 96.76%\n",
      "5\tValidation loss: 0.122852\tBest loss: 0.112957\tAccuracy: 96.05%\n",
      "6\tValidation loss: 0.117114\tBest loss: 0.112957\tAccuracy: 96.52%\n",
      "7\tValidation loss: 0.117726\tBest loss: 0.112957\tAccuracy: 96.60%\n",
      "8\tValidation loss: 0.106021\tBest loss: 0.106021\tAccuracy: 96.64%\n",
      "9\tValidation loss: 0.110391\tBest loss: 0.106021\tAccuracy: 96.72%\n",
      "[CV]  n_neurons=10, learning_rate=0.01, dropout_rate=0.1, batch_size=10, batch_norm_momentum=0.9, activation=<function elu at 0x11408c9d8>, total= 1.5min\n",
      "[CV] n_neurons=10, learning_rate=0.01, dropout_rate=0.1, batch_size=10, batch_norm_momentum=0.9, activation=<function elu at 0x11408c9d8> \n",
      "0\tValidation loss: 0.153853\tBest loss: 0.153853\tAccuracy: 95.47%\n",
      "1\tValidation loss: 0.125103\tBest loss: 0.125103\tAccuracy: 95.82%\n",
      "2\tValidation loss: 0.139697\tBest loss: 0.125103\tAccuracy: 95.62%\n",
      "3\tValidation loss: 0.136753\tBest loss: 0.125103\tAccuracy: 95.39%\n",
      "4\tValidation loss: 0.138651\tBest loss: 0.125103\tAccuracy: 95.54%\n",
      "5\tValidation loss: 0.124609\tBest loss: 0.124609\tAccuracy: 96.25%\n",
      "6\tValidation loss: 0.108407\tBest loss: 0.108407\tAccuracy: 96.52%\n",
      "7\tValidation loss: 0.120530\tBest loss: 0.108407\tAccuracy: 96.05%\n",
      "8\tValidation loss: 0.096694\tBest loss: 0.096694\tAccuracy: 97.11%\n",
      "9\tValidation loss: 0.100880\tBest loss: 0.096694\tAccuracy: 96.87%\n",
      "[CV]  n_neurons=10, learning_rate=0.01, dropout_rate=0.1, batch_size=10, batch_norm_momentum=0.9, activation=<function elu at 0x11408c9d8>, total= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  9.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.145685\tBest loss: 0.145685\tAccuracy: 95.35%\n",
      "1\tValidation loss: 0.126576\tBest loss: 0.126576\tAccuracy: 96.01%\n",
      "2\tValidation loss: 0.113865\tBest loss: 0.113865\tAccuracy: 96.21%\n",
      "3\tValidation loss: 0.119362\tBest loss: 0.113865\tAccuracy: 96.40%\n",
      "4\tValidation loss: 0.103655\tBest loss: 0.103655\tAccuracy: 96.79%\n",
      "5\tValidation loss: 0.097415\tBest loss: 0.097415\tAccuracy: 97.07%\n",
      "6\tValidation loss: 0.095078\tBest loss: 0.095078\tAccuracy: 97.07%\n",
      "7\tValidation loss: 0.103109\tBest loss: 0.095078\tAccuracy: 96.79%\n",
      "8\tValidation loss: 0.102628\tBest loss: 0.095078\tAccuracy: 96.76%\n",
      "9\tValidation loss: 0.104654\tBest loss: 0.095078\tAccuracy: 96.79%\n"
     ]
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    \"n_neurons\": [10],\n",
    "    \"batch_size\": [10],\n",
    "    \"learning_rate\": [0.01],\n",
    "    \"activation\": [tf.nn.relu, tf.nn.elu],\n",
    "    \"dropout_rate\": [0.1],\n",
    "    \"batch_norm_momentum\": [0.9]\n",
    "}\n",
    "\n",
    "\n",
    "random_search = RandomizedSearchCV(DNNClassifier(random_state=42), param_distribs, n_iter=50, fit_params={\"X_valid\": X_valid, \"y_valid\": y_valid, \"n_epochs\": 10},\n",
    "                                random_state=42, verbose=2)\n",
    "random_search.fit(X_train, y_train)\n",
    "y_pred = random_search.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)\n",
    "random_search.best_estimator_.save(\"./model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model doesn't overfit. So dropout of every layer doesn't really help in accuracy improvement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os, sys, time\n",
    "sys.path.append(os.getcwd())\n",
    "from DNNClassifier import DNNClassifier\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "\n",
    "X_train_full = mnist.train.images[mnist.train.labels >= 5]\n",
    "y_train_full = mnist.train.labels[mnist.train.labels >= 5] - 5\n",
    "X_valid_full = mnist.validation.images[mnist.validation.labels >= 5]\n",
    "y_valid_full = mnist.validation.labels[mnist.validation.labels >= 5] - 5\n",
    "X_test = mnist.test.images[mnist.test.labels >= 5]\n",
    "y_test = mnist.test.labels[mnist.test.labels >= 5] - 5\n",
    "\n",
    "def sample_n_instances_per_class(X, y, n=100):\n",
    "    Xs, ys = [], []\n",
    "    for label in np.unique(y):\n",
    "        idx = (y == label)\n",
    "        Xc = X[idx][:n]\n",
    "        yc = y[idx][:n]\n",
    "        Xs.append(Xc)\n",
    "        ys.append(yc)\n",
    "    return np.concatenate(Xs), np.concatenate(ys)\n",
    "\n",
    "X_train, y_train = sample_n_instances_per_class(X_train_full, y_train_full, n=100)\n",
    "X_valid, y_valid = sample_n_instances_per_class(X_valid_full, y_valid_full, n=30)\n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "n_epochs = 1000\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create a new DNN that reuses all the pretrained hidden layers of the previous model, freezes them, and replaces the softmax output layer with a fresh new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 start\n"
     ]
    }
   ],
   "source": [
    "print('Task 1 start')\n",
    "time.sleep(1)\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "restore_saver = tf.train.import_meta_graph(\"./model.meta\")\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "loss = tf.get_default_graph().get_tensor_by_name(\"loss:0\")\n",
    "Y_proba = tf.get_default_graph().get_tensor_by_name(\"Y_proba:0\")\n",
    "logits = Y_proba.op.inputs[0]\n",
    "accuracy = tf.get_default_graph().get_tensor_by_name(\"accuracy:0\")\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"logits\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam2\")\n",
    "training_op = optimizer.minimize(loss, var_list=output_layer_vars)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "five_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train this new DNN on digits 5 to 9, using only 100 images per digit, and time how long it takes. Despite this small number of examples, can you achieve high precision?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2 start\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "0\tValidation loss: 1.613087\tBest loss: 1.613087\tAccuracy: 29.33%\n",
      "1\tValidation loss: 1.381432\tBest loss: 1.381432\tAccuracy: 46.67%\n",
      "2\tValidation loss: 1.263373\tBest loss: 1.263373\tAccuracy: 49.33%\n",
      "3\tValidation loss: 1.193123\tBest loss: 1.193123\tAccuracy: 55.33%\n",
      "4\tValidation loss: 1.147694\tBest loss: 1.147694\tAccuracy: 59.33%\n",
      "5\tValidation loss: 1.115880\tBest loss: 1.115880\tAccuracy: 59.33%\n",
      "6\tValidation loss: 1.102723\tBest loss: 1.102723\tAccuracy: 61.33%\n",
      "7\tValidation loss: 1.088225\tBest loss: 1.088225\tAccuracy: 61.33%\n",
      "8\tValidation loss: 1.087017\tBest loss: 1.087017\tAccuracy: 61.33%\n",
      "9\tValidation loss: 1.079110\tBest loss: 1.079110\tAccuracy: 62.67%\n",
      "10\tValidation loss: 1.066826\tBest loss: 1.066826\tAccuracy: 62.00%\n",
      "11\tValidation loss: 1.067650\tBest loss: 1.066826\tAccuracy: 60.00%\n",
      "12\tValidation loss: 1.077122\tBest loss: 1.066826\tAccuracy: 61.33%\n",
      "13\tValidation loss: 1.064024\tBest loss: 1.064024\tAccuracy: 61.33%\n",
      "14\tValidation loss: 1.058316\tBest loss: 1.058316\tAccuracy: 60.00%\n",
      "15\tValidation loss: 1.064154\tBest loss: 1.058316\tAccuracy: 61.33%\n",
      "16\tValidation loss: 1.050942\tBest loss: 1.050942\tAccuracy: 60.67%\n",
      "17\tValidation loss: 1.057375\tBest loss: 1.050942\tAccuracy: 62.00%\n",
      "18\tValidation loss: 1.049523\tBest loss: 1.049523\tAccuracy: 61.33%\n",
      "19\tValidation loss: 1.048272\tBest loss: 1.048272\tAccuracy: 61.33%\n",
      "20\tValidation loss: 1.045529\tBest loss: 1.045529\tAccuracy: 62.00%\n",
      "21\tValidation loss: 1.047018\tBest loss: 1.045529\tAccuracy: 63.33%\n",
      "22\tValidation loss: 1.036228\tBest loss: 1.036228\tAccuracy: 62.00%\n",
      "23\tValidation loss: 1.040227\tBest loss: 1.036228\tAccuracy: 62.67%\n",
      "24\tValidation loss: 1.042849\tBest loss: 1.036228\tAccuracy: 62.67%\n",
      "25\tValidation loss: 1.037388\tBest loss: 1.036228\tAccuracy: 61.33%\n",
      "26\tValidation loss: 1.042662\tBest loss: 1.036228\tAccuracy: 62.67%\n",
      "27\tValidation loss: 1.034343\tBest loss: 1.034343\tAccuracy: 62.00%\n",
      "28\tValidation loss: 1.032781\tBest loss: 1.032781\tAccuracy: 63.33%\n",
      "29\tValidation loss: 1.030427\tBest loss: 1.030427\tAccuracy: 62.00%\n",
      "30\tValidation loss: 1.025353\tBest loss: 1.025353\tAccuracy: 63.33%\n",
      "31\tValidation loss: 1.034318\tBest loss: 1.025353\tAccuracy: 62.67%\n",
      "32\tValidation loss: 1.027051\tBest loss: 1.025353\tAccuracy: 61.33%\n",
      "33\tValidation loss: 1.026234\tBest loss: 1.025353\tAccuracy: 62.67%\n",
      "34\tValidation loss: 1.024092\tBest loss: 1.024092\tAccuracy: 62.67%\n",
      "35\tValidation loss: 1.020754\tBest loss: 1.020754\tAccuracy: 61.33%\n",
      "36\tValidation loss: 1.022976\tBest loss: 1.020754\tAccuracy: 62.67%\n",
      "37\tValidation loss: 1.022269\tBest loss: 1.020754\tAccuracy: 62.67%\n",
      "38\tValidation loss: 1.017742\tBest loss: 1.017742\tAccuracy: 62.67%\n",
      "39\tValidation loss: 1.022302\tBest loss: 1.017742\tAccuracy: 63.33%\n",
      "40\tValidation loss: 1.014907\tBest loss: 1.014907\tAccuracy: 62.67%\n",
      "41\tValidation loss: 1.021169\tBest loss: 1.014907\tAccuracy: 62.67%\n",
      "42\tValidation loss: 1.011890\tBest loss: 1.011890\tAccuracy: 62.67%\n",
      "43\tValidation loss: 1.009892\tBest loss: 1.009892\tAccuracy: 64.00%\n",
      "44\tValidation loss: 1.013019\tBest loss: 1.009892\tAccuracy: 62.67%\n",
      "45\tValidation loss: 1.014704\tBest loss: 1.009892\tAccuracy: 62.67%\n",
      "46\tValidation loss: 1.014842\tBest loss: 1.009892\tAccuracy: 62.67%\n",
      "47\tValidation loss: 1.008296\tBest loss: 1.008296\tAccuracy: 64.00%\n",
      "48\tValidation loss: 1.018593\tBest loss: 1.008296\tAccuracy: 62.67%\n",
      "49\tValidation loss: 1.000939\tBest loss: 1.000939\tAccuracy: 62.67%\n",
      "50\tValidation loss: 1.001475\tBest loss: 1.000939\tAccuracy: 62.67%\n",
      "51\tValidation loss: 1.001510\tBest loss: 1.000939\tAccuracy: 62.00%\n",
      "52\tValidation loss: 1.011432\tBest loss: 1.000939\tAccuracy: 64.00%\n",
      "53\tValidation loss: 1.005658\tBest loss: 1.000939\tAccuracy: 63.33%\n",
      "54\tValidation loss: 1.013856\tBest loss: 1.000939\tAccuracy: 62.00%\n",
      "55\tValidation loss: 0.998462\tBest loss: 0.998462\tAccuracy: 62.67%\n",
      "56\tValidation loss: 1.004713\tBest loss: 0.998462\tAccuracy: 63.33%\n",
      "57\tValidation loss: 1.001120\tBest loss: 0.998462\tAccuracy: 64.00%\n",
      "58\tValidation loss: 0.997173\tBest loss: 0.997173\tAccuracy: 62.00%\n",
      "59\tValidation loss: 1.005270\tBest loss: 0.997173\tAccuracy: 63.33%\n",
      "60\tValidation loss: 0.999767\tBest loss: 0.997173\tAccuracy: 63.33%\n",
      "61\tValidation loss: 1.003569\tBest loss: 0.997173\tAccuracy: 64.00%\n",
      "62\tValidation loss: 0.993497\tBest loss: 0.993497\tAccuracy: 64.00%\n",
      "63\tValidation loss: 0.994626\tBest loss: 0.993497\tAccuracy: 64.00%\n",
      "64\tValidation loss: 0.998936\tBest loss: 0.993497\tAccuracy: 62.67%\n",
      "65\tValidation loss: 1.000539\tBest loss: 0.993497\tAccuracy: 63.33%\n",
      "66\tValidation loss: 0.982740\tBest loss: 0.982740\tAccuracy: 64.67%\n",
      "67\tValidation loss: 0.992847\tBest loss: 0.982740\tAccuracy: 64.00%\n",
      "68\tValidation loss: 0.991429\tBest loss: 0.982740\tAccuracy: 64.00%\n",
      "69\tValidation loss: 0.992705\tBest loss: 0.982740\tAccuracy: 63.33%\n",
      "70\tValidation loss: 0.999224\tBest loss: 0.982740\tAccuracy: 62.67%\n",
      "71\tValidation loss: 0.989581\tBest loss: 0.982740\tAccuracy: 63.33%\n",
      "72\tValidation loss: 0.992876\tBest loss: 0.982740\tAccuracy: 62.67%\n",
      "73\tValidation loss: 0.984414\tBest loss: 0.982740\tAccuracy: 64.00%\n",
      "74\tValidation loss: 0.992310\tBest loss: 0.982740\tAccuracy: 64.00%\n",
      "75\tValidation loss: 0.979271\tBest loss: 0.979271\tAccuracy: 64.00%\n",
      "76\tValidation loss: 0.992248\tBest loss: 0.979271\tAccuracy: 63.33%\n",
      "77\tValidation loss: 0.983496\tBest loss: 0.979271\tAccuracy: 64.00%\n",
      "78\tValidation loss: 0.997425\tBest loss: 0.979271\tAccuracy: 62.67%\n",
      "79\tValidation loss: 0.990998\tBest loss: 0.979271\tAccuracy: 64.00%\n",
      "80\tValidation loss: 0.988853\tBest loss: 0.979271\tAccuracy: 64.00%\n",
      "81\tValidation loss: 0.981559\tBest loss: 0.979271\tAccuracy: 62.67%\n",
      "82\tValidation loss: 0.989328\tBest loss: 0.979271\tAccuracy: 64.00%\n",
      "83\tValidation loss: 0.985332\tBest loss: 0.979271\tAccuracy: 64.67%\n",
      "84\tValidation loss: 0.989753\tBest loss: 0.979271\tAccuracy: 63.33%\n",
      "85\tValidation loss: 0.983861\tBest loss: 0.979271\tAccuracy: 64.00%\n",
      "86\tValidation loss: 0.986919\tBest loss: 0.979271\tAccuracy: 62.67%\n",
      "87\tValidation loss: 0.979993\tBest loss: 0.979271\tAccuracy: 64.67%\n",
      "88\tValidation loss: 0.982787\tBest loss: 0.979271\tAccuracy: 64.00%\n",
      "89\tValidation loss: 0.983698\tBest loss: 0.979271\tAccuracy: 64.67%\n",
      "90\tValidation loss: 0.980710\tBest loss: 0.979271\tAccuracy: 64.00%\n",
      "91\tValidation loss: 0.978751\tBest loss: 0.978751\tAccuracy: 65.33%\n",
      "92\tValidation loss: 0.984063\tBest loss: 0.978751\tAccuracy: 64.00%\n",
      "93\tValidation loss: 0.985467\tBest loss: 0.978751\tAccuracy: 64.67%\n",
      "94\tValidation loss: 0.978364\tBest loss: 0.978364\tAccuracy: 64.67%\n",
      "95\tValidation loss: 0.979968\tBest loss: 0.978364\tAccuracy: 65.33%\n",
      "96\tValidation loss: 0.978601\tBest loss: 0.978364\tAccuracy: 64.00%\n",
      "97\tValidation loss: 0.973175\tBest loss: 0.973175\tAccuracy: 64.67%\n",
      "98\tValidation loss: 0.975766\tBest loss: 0.973175\tAccuracy: 64.67%\n",
      "99\tValidation loss: 0.982063\tBest loss: 0.973175\tAccuracy: 64.00%\n",
      "100\tValidation loss: 0.977910\tBest loss: 0.973175\tAccuracy: 64.67%\n",
      "101\tValidation loss: 0.979142\tBest loss: 0.973175\tAccuracy: 64.00%\n",
      "102\tValidation loss: 0.967174\tBest loss: 0.967174\tAccuracy: 66.00%\n",
      "103\tValidation loss: 0.979581\tBest loss: 0.967174\tAccuracy: 64.67%\n",
      "104\tValidation loss: 0.973876\tBest loss: 0.967174\tAccuracy: 65.33%\n",
      "105\tValidation loss: 0.969690\tBest loss: 0.967174\tAccuracy: 66.00%\n",
      "106\tValidation loss: 0.976976\tBest loss: 0.967174\tAccuracy: 64.00%\n",
      "107\tValidation loss: 0.980340\tBest loss: 0.967174\tAccuracy: 65.33%\n",
      "108\tValidation loss: 0.973690\tBest loss: 0.967174\tAccuracy: 64.67%\n",
      "109\tValidation loss: 0.975122\tBest loss: 0.967174\tAccuracy: 64.00%\n",
      "110\tValidation loss: 0.972888\tBest loss: 0.967174\tAccuracy: 64.67%\n",
      "111\tValidation loss: 0.981449\tBest loss: 0.967174\tAccuracy: 64.00%\n",
      "112\tValidation loss: 0.973330\tBest loss: 0.967174\tAccuracy: 65.33%\n",
      "113\tValidation loss: 0.970983\tBest loss: 0.967174\tAccuracy: 64.67%\n",
      "114\tValidation loss: 0.971071\tBest loss: 0.967174\tAccuracy: 65.33%\n",
      "115\tValidation loss: 0.975271\tBest loss: 0.967174\tAccuracy: 64.67%\n",
      "116\tValidation loss: 0.969811\tBest loss: 0.967174\tAccuracy: 66.00%\n",
      "117\tValidation loss: 0.977080\tBest loss: 0.967174\tAccuracy: 64.00%\n",
      "118\tValidation loss: 0.964836\tBest loss: 0.964836\tAccuracy: 66.00%\n",
      "119\tValidation loss: 0.971169\tBest loss: 0.964836\tAccuracy: 65.33%\n",
      "120\tValidation loss: 0.971206\tBest loss: 0.964836\tAccuracy: 66.00%\n",
      "121\tValidation loss: 0.976961\tBest loss: 0.964836\tAccuracy: 64.67%\n",
      "122\tValidation loss: 0.972565\tBest loss: 0.964836\tAccuracy: 65.33%\n",
      "123\tValidation loss: 0.972619\tBest loss: 0.964836\tAccuracy: 65.33%\n",
      "124\tValidation loss: 0.977501\tBest loss: 0.964836\tAccuracy: 64.67%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\tValidation loss: 0.968067\tBest loss: 0.964836\tAccuracy: 65.33%\n",
      "126\tValidation loss: 0.966442\tBest loss: 0.964836\tAccuracy: 65.33%\n",
      "127\tValidation loss: 0.974345\tBest loss: 0.964836\tAccuracy: 64.67%\n",
      "128\tValidation loss: 0.968021\tBest loss: 0.964836\tAccuracy: 65.33%\n",
      "129\tValidation loss: 0.970689\tBest loss: 0.964836\tAccuracy: 65.33%\n",
      "130\tValidation loss: 0.968800\tBest loss: 0.964836\tAccuracy: 65.33%\n",
      "131\tValidation loss: 0.970321\tBest loss: 0.964836\tAccuracy: 65.33%\n",
      "132\tValidation loss: 0.963780\tBest loss: 0.963780\tAccuracy: 65.33%\n",
      "133\tValidation loss: 0.969368\tBest loss: 0.963780\tAccuracy: 65.33%\n",
      "134\tValidation loss: 0.962952\tBest loss: 0.962952\tAccuracy: 65.33%\n",
      "135\tValidation loss: 0.971286\tBest loss: 0.962952\tAccuracy: 65.33%\n",
      "136\tValidation loss: 0.973394\tBest loss: 0.962952\tAccuracy: 65.33%\n",
      "137\tValidation loss: 0.975058\tBest loss: 0.962952\tAccuracy: 64.67%\n",
      "138\tValidation loss: 0.964954\tBest loss: 0.962952\tAccuracy: 66.00%\n",
      "139\tValidation loss: 0.966920\tBest loss: 0.962952\tAccuracy: 65.33%\n",
      "140\tValidation loss: 0.959813\tBest loss: 0.959813\tAccuracy: 66.00%\n",
      "141\tValidation loss: 0.967456\tBest loss: 0.959813\tAccuracy: 65.33%\n",
      "142\tValidation loss: 0.965566\tBest loss: 0.959813\tAccuracy: 65.33%\n",
      "143\tValidation loss: 0.971931\tBest loss: 0.959813\tAccuracy: 65.33%\n",
      "144\tValidation loss: 0.964485\tBest loss: 0.959813\tAccuracy: 66.00%\n",
      "145\tValidation loss: 0.966090\tBest loss: 0.959813\tAccuracy: 65.33%\n",
      "146\tValidation loss: 0.966078\tBest loss: 0.959813\tAccuracy: 65.33%\n",
      "147\tValidation loss: 0.961176\tBest loss: 0.959813\tAccuracy: 66.00%\n",
      "148\tValidation loss: 0.970267\tBest loss: 0.959813\tAccuracy: 64.67%\n",
      "149\tValidation loss: 0.971166\tBest loss: 0.959813\tAccuracy: 64.67%\n",
      "150\tValidation loss: 0.957229\tBest loss: 0.957229\tAccuracy: 66.00%\n",
      "151\tValidation loss: 0.966263\tBest loss: 0.957229\tAccuracy: 64.67%\n",
      "152\tValidation loss: 0.965274\tBest loss: 0.957229\tAccuracy: 66.00%\n",
      "153\tValidation loss: 0.958892\tBest loss: 0.957229\tAccuracy: 67.33%\n",
      "154\tValidation loss: 0.965967\tBest loss: 0.957229\tAccuracy: 66.00%\n",
      "155\tValidation loss: 0.961776\tBest loss: 0.957229\tAccuracy: 66.00%\n",
      "156\tValidation loss: 0.969563\tBest loss: 0.957229\tAccuracy: 65.33%\n",
      "157\tValidation loss: 0.963553\tBest loss: 0.957229\tAccuracy: 66.00%\n",
      "158\tValidation loss: 0.966841\tBest loss: 0.957229\tAccuracy: 65.33%\n",
      "159\tValidation loss: 0.958355\tBest loss: 0.957229\tAccuracy: 66.00%\n",
      "160\tValidation loss: 0.971811\tBest loss: 0.957229\tAccuracy: 64.67%\n",
      "161\tValidation loss: 0.964308\tBest loss: 0.957229\tAccuracy: 65.33%\n",
      "162\tValidation loss: 0.964056\tBest loss: 0.957229\tAccuracy: 66.00%\n",
      "163\tValidation loss: 0.969644\tBest loss: 0.957229\tAccuracy: 66.00%\n",
      "164\tValidation loss: 0.962869\tBest loss: 0.957229\tAccuracy: 66.00%\n",
      "165\tValidation loss: 0.960129\tBest loss: 0.957229\tAccuracy: 66.00%\n",
      "166\tValidation loss: 0.962905\tBest loss: 0.957229\tAccuracy: 66.00%\n",
      "167\tValidation loss: 0.972655\tBest loss: 0.957229\tAccuracy: 64.67%\n",
      "168\tValidation loss: 0.962571\tBest loss: 0.957229\tAccuracy: 65.33%\n",
      "169\tValidation loss: 0.962106\tBest loss: 0.957229\tAccuracy: 66.00%\n",
      "170\tValidation loss: 0.966652\tBest loss: 0.957229\tAccuracy: 66.00%\n",
      "Early stopping!\n",
      "Total training time: 14.3s\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_five_frozen\n",
      "Final test accuracy: 61.39%\n"
     ]
    }
   ],
   "source": [
    "print('Task 2 start')\n",
    "time.sleep(1)\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./model\")\n",
    "    for var in output_layer_vars:\n",
    "        var.initializer.run()\n",
    "    t0 = time.time()\n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train) // batch_size):\n",
    "            X_batch, y_batch = X_train[rnd_indices], y_train[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid, y: y_valid})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = five_frozen_saver.save(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "    t1 = time.time()\n",
    "    print(\"Total training time: {:.1f}s\".format(t1 - t0))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    five_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Despite this small number of examples, it is difficult to get high precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Try caching the frozen layers, and train the model again: how much faster is it now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 3 start\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "0\tValidation loss: 1.605368\tBest loss: 1.605368\tAccuracy: 30.00%\n",
      "1\tValidation loss: 1.385463\tBest loss: 1.385463\tAccuracy: 46.67%\n",
      "2\tValidation loss: 1.256262\tBest loss: 1.256262\tAccuracy: 50.00%\n",
      "3\tValidation loss: 1.188582\tBest loss: 1.188582\tAccuracy: 56.00%\n",
      "4\tValidation loss: 1.150881\tBest loss: 1.150881\tAccuracy: 58.00%\n",
      "5\tValidation loss: 1.116827\tBest loss: 1.116827\tAccuracy: 60.00%\n",
      "6\tValidation loss: 1.104238\tBest loss: 1.104238\tAccuracy: 63.33%\n",
      "7\tValidation loss: 1.092081\tBest loss: 1.092081\tAccuracy: 61.33%\n",
      "8\tValidation loss: 1.081479\tBest loss: 1.081479\tAccuracy: 62.67%\n",
      "9\tValidation loss: 1.074789\tBest loss: 1.074789\tAccuracy: 60.67%\n",
      "10\tValidation loss: 1.069879\tBest loss: 1.069879\tAccuracy: 64.00%\n",
      "11\tValidation loss: 1.073716\tBest loss: 1.069879\tAccuracy: 60.67%\n",
      "12\tValidation loss: 1.062565\tBest loss: 1.062565\tAccuracy: 62.00%\n",
      "13\tValidation loss: 1.066350\tBest loss: 1.062565\tAccuracy: 60.00%\n",
      "14\tValidation loss: 1.056609\tBest loss: 1.056609\tAccuracy: 61.33%\n",
      "15\tValidation loss: 1.058418\tBest loss: 1.056609\tAccuracy: 59.33%\n",
      "16\tValidation loss: 1.059483\tBest loss: 1.056609\tAccuracy: 61.33%\n",
      "17\tValidation loss: 1.059737\tBest loss: 1.056609\tAccuracy: 61.33%\n",
      "18\tValidation loss: 1.055966\tBest loss: 1.055966\tAccuracy: 60.67%\n",
      "19\tValidation loss: 1.040891\tBest loss: 1.040891\tAccuracy: 62.00%\n",
      "20\tValidation loss: 1.045567\tBest loss: 1.040891\tAccuracy: 62.00%\n",
      "21\tValidation loss: 1.038696\tBest loss: 1.038696\tAccuracy: 62.00%\n",
      "22\tValidation loss: 1.046581\tBest loss: 1.038696\tAccuracy: 61.33%\n",
      "23\tValidation loss: 1.043234\tBest loss: 1.038696\tAccuracy: 63.33%\n",
      "24\tValidation loss: 1.039848\tBest loss: 1.038696\tAccuracy: 62.00%\n",
      "25\tValidation loss: 1.039360\tBest loss: 1.038696\tAccuracy: 62.67%\n",
      "26\tValidation loss: 1.040052\tBest loss: 1.038696\tAccuracy: 62.67%\n",
      "27\tValidation loss: 1.031527\tBest loss: 1.031527\tAccuracy: 63.33%\n",
      "28\tValidation loss: 1.036656\tBest loss: 1.031527\tAccuracy: 63.33%\n",
      "29\tValidation loss: 1.029742\tBest loss: 1.029742\tAccuracy: 62.67%\n",
      "30\tValidation loss: 1.032580\tBest loss: 1.029742\tAccuracy: 62.67%\n",
      "31\tValidation loss: 1.029974\tBest loss: 1.029742\tAccuracy: 62.67%\n",
      "32\tValidation loss: 1.035282\tBest loss: 1.029742\tAccuracy: 62.67%\n",
      "33\tValidation loss: 1.016941\tBest loss: 1.016941\tAccuracy: 62.00%\n",
      "34\tValidation loss: 1.028436\tBest loss: 1.016941\tAccuracy: 62.67%\n",
      "35\tValidation loss: 1.024982\tBest loss: 1.016941\tAccuracy: 63.33%\n",
      "36\tValidation loss: 1.022361\tBest loss: 1.016941\tAccuracy: 62.67%\n",
      "37\tValidation loss: 1.027548\tBest loss: 1.016941\tAccuracy: 62.67%\n",
      "38\tValidation loss: 1.019210\tBest loss: 1.016941\tAccuracy: 62.67%\n",
      "39\tValidation loss: 1.019304\tBest loss: 1.016941\tAccuracy: 62.67%\n",
      "40\tValidation loss: 1.020188\tBest loss: 1.016941\tAccuracy: 62.67%\n",
      "41\tValidation loss: 1.016891\tBest loss: 1.016891\tAccuracy: 62.67%\n",
      "42\tValidation loss: 1.015791\tBest loss: 1.015791\tAccuracy: 62.67%\n",
      "43\tValidation loss: 1.016747\tBest loss: 1.015791\tAccuracy: 62.67%\n",
      "44\tValidation loss: 1.011768\tBest loss: 1.011768\tAccuracy: 63.33%\n",
      "45\tValidation loss: 1.018077\tBest loss: 1.011768\tAccuracy: 62.67%\n",
      "46\tValidation loss: 1.010285\tBest loss: 1.010285\tAccuracy: 62.67%\n",
      "47\tValidation loss: 1.011489\tBest loss: 1.010285\tAccuracy: 64.67%\n",
      "48\tValidation loss: 1.006479\tBest loss: 1.006479\tAccuracy: 62.67%\n",
      "49\tValidation loss: 1.014786\tBest loss: 1.006479\tAccuracy: 64.00%\n",
      "50\tValidation loss: 1.007482\tBest loss: 1.006479\tAccuracy: 64.00%\n",
      "51\tValidation loss: 1.002753\tBest loss: 1.002753\tAccuracy: 63.33%\n",
      "52\tValidation loss: 0.999208\tBest loss: 0.999208\tAccuracy: 62.67%\n",
      "53\tValidation loss: 1.009403\tBest loss: 0.999208\tAccuracy: 62.67%\n",
      "54\tValidation loss: 1.010118\tBest loss: 0.999208\tAccuracy: 62.00%\n",
      "55\tValidation loss: 1.008072\tBest loss: 0.999208\tAccuracy: 63.33%\n",
      "56\tValidation loss: 1.003930\tBest loss: 0.999208\tAccuracy: 64.00%\n",
      "57\tValidation loss: 0.998345\tBest loss: 0.998345\tAccuracy: 64.00%\n",
      "58\tValidation loss: 0.997706\tBest loss: 0.997706\tAccuracy: 63.33%\n",
      "59\tValidation loss: 1.008745\tBest loss: 0.997706\tAccuracy: 63.33%\n",
      "60\tValidation loss: 1.000394\tBest loss: 0.997706\tAccuracy: 64.00%\n",
      "61\tValidation loss: 0.998294\tBest loss: 0.997706\tAccuracy: 63.33%\n",
      "62\tValidation loss: 0.991019\tBest loss: 0.991019\tAccuracy: 64.00%\n",
      "63\tValidation loss: 1.000728\tBest loss: 0.991019\tAccuracy: 64.00%\n",
      "64\tValidation loss: 0.992270\tBest loss: 0.991019\tAccuracy: 64.00%\n",
      "65\tValidation loss: 0.996934\tBest loss: 0.991019\tAccuracy: 63.33%\n",
      "66\tValidation loss: 0.998352\tBest loss: 0.991019\tAccuracy: 63.33%\n",
      "67\tValidation loss: 0.994098\tBest loss: 0.991019\tAccuracy: 64.00%\n",
      "68\tValidation loss: 0.995274\tBest loss: 0.991019\tAccuracy: 62.67%\n",
      "69\tValidation loss: 0.991102\tBest loss: 0.991019\tAccuracy: 64.00%\n",
      "70\tValidation loss: 0.996545\tBest loss: 0.991019\tAccuracy: 63.33%\n",
      "71\tValidation loss: 0.996670\tBest loss: 0.991019\tAccuracy: 63.33%\n",
      "72\tValidation loss: 0.987389\tBest loss: 0.987389\tAccuracy: 63.33%\n",
      "73\tValidation loss: 1.000057\tBest loss: 0.987389\tAccuracy: 63.33%\n",
      "74\tValidation loss: 0.989435\tBest loss: 0.987389\tAccuracy: 64.00%\n",
      "75\tValidation loss: 0.988553\tBest loss: 0.987389\tAccuracy: 63.33%\n",
      "76\tValidation loss: 0.987093\tBest loss: 0.987093\tAccuracy: 64.00%\n",
      "77\tValidation loss: 0.987611\tBest loss: 0.987093\tAccuracy: 64.00%\n",
      "78\tValidation loss: 0.988484\tBest loss: 0.987093\tAccuracy: 63.33%\n",
      "79\tValidation loss: 0.988280\tBest loss: 0.987093\tAccuracy: 63.33%\n",
      "80\tValidation loss: 0.985013\tBest loss: 0.985013\tAccuracy: 63.33%\n",
      "81\tValidation loss: 0.982254\tBest loss: 0.982254\tAccuracy: 63.33%\n",
      "82\tValidation loss: 0.986696\tBest loss: 0.982254\tAccuracy: 64.00%\n",
      "83\tValidation loss: 0.991375\tBest loss: 0.982254\tAccuracy: 64.00%\n",
      "84\tValidation loss: 0.983012\tBest loss: 0.982254\tAccuracy: 63.33%\n",
      "85\tValidation loss: 0.977815\tBest loss: 0.977815\tAccuracy: 64.67%\n",
      "86\tValidation loss: 0.983643\tBest loss: 0.977815\tAccuracy: 63.33%\n",
      "87\tValidation loss: 0.986471\tBest loss: 0.977815\tAccuracy: 64.00%\n",
      "88\tValidation loss: 0.978441\tBest loss: 0.977815\tAccuracy: 64.67%\n",
      "89\tValidation loss: 0.981286\tBest loss: 0.977815\tAccuracy: 63.33%\n",
      "90\tValidation loss: 0.985700\tBest loss: 0.977815\tAccuracy: 64.67%\n",
      "91\tValidation loss: 0.985040\tBest loss: 0.977815\tAccuracy: 63.33%\n",
      "92\tValidation loss: 0.973572\tBest loss: 0.973572\tAccuracy: 64.67%\n",
      "93\tValidation loss: 0.980801\tBest loss: 0.973572\tAccuracy: 65.33%\n",
      "94\tValidation loss: 0.981868\tBest loss: 0.973572\tAccuracy: 64.00%\n",
      "95\tValidation loss: 0.979777\tBest loss: 0.973572\tAccuracy: 64.67%\n",
      "96\tValidation loss: 0.990871\tBest loss: 0.973572\tAccuracy: 64.67%\n",
      "97\tValidation loss: 0.974014\tBest loss: 0.973572\tAccuracy: 65.33%\n",
      "98\tValidation loss: 0.979213\tBest loss: 0.973572\tAccuracy: 64.00%\n",
      "99\tValidation loss: 0.981762\tBest loss: 0.973572\tAccuracy: 64.00%\n",
      "100\tValidation loss: 0.975203\tBest loss: 0.973572\tAccuracy: 65.33%\n",
      "101\tValidation loss: 0.983100\tBest loss: 0.973572\tAccuracy: 64.00%\n",
      "102\tValidation loss: 0.977682\tBest loss: 0.973572\tAccuracy: 64.00%\n",
      "103\tValidation loss: 0.981142\tBest loss: 0.973572\tAccuracy: 64.00%\n",
      "104\tValidation loss: 0.971698\tBest loss: 0.971698\tAccuracy: 65.33%\n",
      "105\tValidation loss: 0.973615\tBest loss: 0.971698\tAccuracy: 65.33%\n",
      "106\tValidation loss: 0.981118\tBest loss: 0.971698\tAccuracy: 64.00%\n",
      "107\tValidation loss: 0.975341\tBest loss: 0.971698\tAccuracy: 65.33%\n",
      "108\tValidation loss: 0.971212\tBest loss: 0.971212\tAccuracy: 65.33%\n",
      "109\tValidation loss: 0.974082\tBest loss: 0.971212\tAccuracy: 66.00%\n",
      "110\tValidation loss: 0.978388\tBest loss: 0.971212\tAccuracy: 64.00%\n",
      "111\tValidation loss: 0.968151\tBest loss: 0.968151\tAccuracy: 65.33%\n",
      "112\tValidation loss: 0.976231\tBest loss: 0.968151\tAccuracy: 65.33%\n",
      "113\tValidation loss: 0.977535\tBest loss: 0.968151\tAccuracy: 64.00%\n",
      "114\tValidation loss: 0.978763\tBest loss: 0.968151\tAccuracy: 64.67%\n",
      "115\tValidation loss: 0.976235\tBest loss: 0.968151\tAccuracy: 64.67%\n",
      "116\tValidation loss: 0.970346\tBest loss: 0.968151\tAccuracy: 65.33%\n",
      "117\tValidation loss: 0.966594\tBest loss: 0.966594\tAccuracy: 65.33%\n",
      "118\tValidation loss: 0.969743\tBest loss: 0.966594\tAccuracy: 65.33%\n",
      "119\tValidation loss: 0.977077\tBest loss: 0.966594\tAccuracy: 64.67%\n",
      "120\tValidation loss: 0.967294\tBest loss: 0.966594\tAccuracy: 65.33%\n",
      "121\tValidation loss: 0.967683\tBest loss: 0.966594\tAccuracy: 65.33%\n",
      "122\tValidation loss: 0.969343\tBest loss: 0.966594\tAccuracy: 65.33%\n",
      "123\tValidation loss: 0.971492\tBest loss: 0.966594\tAccuracy: 65.33%\n",
      "124\tValidation loss: 0.971334\tBest loss: 0.966594\tAccuracy: 65.33%\n",
      "125\tValidation loss: 0.973820\tBest loss: 0.966594\tAccuracy: 65.33%\n",
      "126\tValidation loss: 0.968077\tBest loss: 0.966594\tAccuracy: 65.33%\n",
      "127\tValidation loss: 0.969448\tBest loss: 0.966594\tAccuracy: 65.33%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\tValidation loss: 0.962128\tBest loss: 0.962128\tAccuracy: 65.33%\n",
      "129\tValidation loss: 0.966995\tBest loss: 0.962128\tAccuracy: 65.33%\n",
      "130\tValidation loss: 0.972174\tBest loss: 0.962128\tAccuracy: 64.67%\n",
      "131\tValidation loss: 0.973569\tBest loss: 0.962128\tAccuracy: 65.33%\n",
      "132\tValidation loss: 0.968293\tBest loss: 0.962128\tAccuracy: 65.33%\n",
      "133\tValidation loss: 0.972234\tBest loss: 0.962128\tAccuracy: 64.67%\n",
      "134\tValidation loss: 0.970420\tBest loss: 0.962128\tAccuracy: 65.33%\n",
      "135\tValidation loss: 0.974617\tBest loss: 0.962128\tAccuracy: 64.67%\n",
      "136\tValidation loss: 0.967816\tBest loss: 0.962128\tAccuracy: 65.33%\n",
      "137\tValidation loss: 0.963773\tBest loss: 0.962128\tAccuracy: 65.33%\n",
      "138\tValidation loss: 0.968723\tBest loss: 0.962128\tAccuracy: 65.33%\n",
      "139\tValidation loss: 0.974694\tBest loss: 0.962128\tAccuracy: 64.67%\n",
      "140\tValidation loss: 0.964783\tBest loss: 0.962128\tAccuracy: 66.00%\n",
      "141\tValidation loss: 0.967297\tBest loss: 0.962128\tAccuracy: 65.33%\n",
      "142\tValidation loss: 0.971275\tBest loss: 0.962128\tAccuracy: 64.67%\n",
      "143\tValidation loss: 0.963914\tBest loss: 0.962128\tAccuracy: 65.33%\n",
      "144\tValidation loss: 0.971887\tBest loss: 0.962128\tAccuracy: 65.33%\n",
      "145\tValidation loss: 0.964770\tBest loss: 0.962128\tAccuracy: 65.33%\n",
      "146\tValidation loss: 0.969574\tBest loss: 0.962128\tAccuracy: 65.33%\n",
      "147\tValidation loss: 0.966293\tBest loss: 0.962128\tAccuracy: 65.33%\n",
      "148\tValidation loss: 0.963541\tBest loss: 0.962128\tAccuracy: 65.33%\n",
      "Early stopping!\n",
      "Total training time: 17.0s\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_five_frozen\n",
      "Final test accuracy: 61.55%\n"
     ]
    }
   ],
   "source": [
    "print('Task 3 start')\n",
    "time.sleep(1)\n",
    "\n",
    "hidden5_out = tf.get_default_graph().get_tensor_by_name(\"hidden5_out:0\")\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./model\")\n",
    "    for var in output_layer_vars:\n",
    "        var.initializer.run()\n",
    "    t0 = time.time()\n",
    "    hidden5_train = hidden5_out.eval(feed_dict={X: X_train, y: y_train})\n",
    "    hidden5_valid = hidden5_out.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train) // batch_size):\n",
    "            h5_batch, y_batch = hidden5_train[rnd_indices], y_train[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={hidden5_out: h5_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={hidden5_out: hidden5_valid, y: y_valid})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = five_frozen_saver.save(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "    t1 = time.time()\n",
    "    print(\"Total training time: {:.1f}s\".format(t1 - t0))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    five_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very fast. It took about 10 seconds to finish the job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Try again reusing just four hidden layers instead of five. Can you achieve a higher precision?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 4 start\n",
      "INFO:tensorflow:Restoring parameters from ./model\n",
      "0\tValidation loss: 1.367993\tBest loss: 1.367993\tAccuracy: 50.67%\n",
      "1\tValidation loss: 1.242862\tBest loss: 1.242862\tAccuracy: 57.33%\n",
      "2\tValidation loss: 1.187196\tBest loss: 1.187196\tAccuracy: 58.00%\n",
      "3\tValidation loss: 1.154578\tBest loss: 1.154578\tAccuracy: 56.67%\n",
      "4\tValidation loss: 1.127822\tBest loss: 1.127822\tAccuracy: 57.33%\n",
      "5\tValidation loss: 1.110844\tBest loss: 1.110844\tAccuracy: 56.67%\n",
      "6\tValidation loss: 1.100803\tBest loss: 1.100803\tAccuracy: 60.00%\n",
      "7\tValidation loss: 1.089174\tBest loss: 1.089174\tAccuracy: 61.33%\n",
      "8\tValidation loss: 1.088616\tBest loss: 1.088616\tAccuracy: 61.33%\n",
      "9\tValidation loss: 1.081465\tBest loss: 1.081465\tAccuracy: 60.00%\n",
      "10\tValidation loss: 1.069525\tBest loss: 1.069525\tAccuracy: 60.00%\n",
      "11\tValidation loss: 1.068703\tBest loss: 1.068703\tAccuracy: 61.33%\n",
      "12\tValidation loss: 1.074007\tBest loss: 1.068703\tAccuracy: 61.33%\n",
      "13\tValidation loss: 1.063972\tBest loss: 1.063972\tAccuracy: 60.67%\n",
      "14\tValidation loss: 1.061230\tBest loss: 1.061230\tAccuracy: 60.00%\n",
      "15\tValidation loss: 1.063235\tBest loss: 1.061230\tAccuracy: 60.67%\n",
      "16\tValidation loss: 1.051966\tBest loss: 1.051966\tAccuracy: 60.67%\n",
      "17\tValidation loss: 1.056349\tBest loss: 1.051966\tAccuracy: 60.67%\n",
      "18\tValidation loss: 1.047854\tBest loss: 1.047854\tAccuracy: 60.67%\n",
      "19\tValidation loss: 1.049166\tBest loss: 1.047854\tAccuracy: 60.67%\n",
      "20\tValidation loss: 1.047115\tBest loss: 1.047115\tAccuracy: 60.00%\n",
      "21\tValidation loss: 1.044735\tBest loss: 1.044735\tAccuracy: 60.00%\n",
      "22\tValidation loss: 1.039767\tBest loss: 1.039767\tAccuracy: 60.00%\n",
      "23\tValidation loss: 1.039313\tBest loss: 1.039313\tAccuracy: 60.00%\n",
      "24\tValidation loss: 1.042361\tBest loss: 1.039313\tAccuracy: 60.00%\n",
      "25\tValidation loss: 1.039794\tBest loss: 1.039313\tAccuracy: 60.00%\n",
      "26\tValidation loss: 1.039844\tBest loss: 1.039313\tAccuracy: 60.67%\n",
      "27\tValidation loss: 1.036224\tBest loss: 1.036224\tAccuracy: 60.67%\n",
      "28\tValidation loss: 1.035809\tBest loss: 1.035809\tAccuracy: 61.33%\n",
      "29\tValidation loss: 1.034595\tBest loss: 1.034595\tAccuracy: 60.67%\n",
      "30\tValidation loss: 1.029008\tBest loss: 1.029008\tAccuracy: 61.33%\n",
      "31\tValidation loss: 1.035575\tBest loss: 1.029008\tAccuracy: 60.67%\n",
      "32\tValidation loss: 1.031819\tBest loss: 1.029008\tAccuracy: 61.33%\n",
      "33\tValidation loss: 1.029887\tBest loss: 1.029008\tAccuracy: 60.67%\n",
      "34\tValidation loss: 1.027963\tBest loss: 1.027963\tAccuracy: 61.33%\n",
      "35\tValidation loss: 1.027534\tBest loss: 1.027534\tAccuracy: 60.67%\n",
      "36\tValidation loss: 1.026009\tBest loss: 1.026009\tAccuracy: 61.33%\n",
      "37\tValidation loss: 1.024282\tBest loss: 1.024282\tAccuracy: 61.33%\n",
      "38\tValidation loss: 1.022878\tBest loss: 1.022878\tAccuracy: 62.00%\n",
      "39\tValidation loss: 1.024827\tBest loss: 1.022878\tAccuracy: 62.00%\n",
      "40\tValidation loss: 1.022287\tBest loss: 1.022287\tAccuracy: 62.67%\n",
      "41\tValidation loss: 1.023734\tBest loss: 1.022287\tAccuracy: 61.33%\n",
      "42\tValidation loss: 1.019627\tBest loss: 1.019627\tAccuracy: 62.00%\n",
      "43\tValidation loss: 1.017807\tBest loss: 1.017807\tAccuracy: 62.00%\n",
      "44\tValidation loss: 1.020009\tBest loss: 1.017807\tAccuracy: 62.00%\n",
      "45\tValidation loss: 1.020488\tBest loss: 1.017807\tAccuracy: 60.67%\n",
      "46\tValidation loss: 1.018985\tBest loss: 1.017807\tAccuracy: 62.00%\n",
      "47\tValidation loss: 1.015072\tBest loss: 1.015072\tAccuracy: 61.33%\n",
      "48\tValidation loss: 1.020786\tBest loss: 1.015072\tAccuracy: 62.00%\n",
      "49\tValidation loss: 1.010662\tBest loss: 1.010662\tAccuracy: 61.33%\n",
      "50\tValidation loss: 1.009641\tBest loss: 1.009641\tAccuracy: 60.67%\n",
      "51\tValidation loss: 1.011392\tBest loss: 1.009641\tAccuracy: 61.33%\n",
      "52\tValidation loss: 1.019654\tBest loss: 1.009641\tAccuracy: 60.67%\n",
      "53\tValidation loss: 1.012280\tBest loss: 1.009641\tAccuracy: 61.33%\n",
      "54\tValidation loss: 1.016502\tBest loss: 1.009641\tAccuracy: 62.67%\n",
      "55\tValidation loss: 1.008301\tBest loss: 1.008301\tAccuracy: 61.33%\n",
      "56\tValidation loss: 1.012291\tBest loss: 1.008301\tAccuracy: 62.67%\n",
      "57\tValidation loss: 1.012431\tBest loss: 1.008301\tAccuracy: 62.00%\n",
      "58\tValidation loss: 1.004998\tBest loss: 1.004998\tAccuracy: 62.00%\n",
      "59\tValidation loss: 1.011335\tBest loss: 1.004998\tAccuracy: 62.67%\n",
      "60\tValidation loss: 1.010925\tBest loss: 1.004998\tAccuracy: 61.33%\n",
      "61\tValidation loss: 1.013409\tBest loss: 1.004998\tAccuracy: 61.33%\n",
      "62\tValidation loss: 1.003016\tBest loss: 1.003016\tAccuracy: 63.33%\n",
      "63\tValidation loss: 1.007023\tBest loss: 1.003016\tAccuracy: 61.33%\n",
      "64\tValidation loss: 1.005845\tBest loss: 1.003016\tAccuracy: 63.33%\n",
      "65\tValidation loss: 1.008089\tBest loss: 1.003016\tAccuracy: 62.67%\n",
      "66\tValidation loss: 0.997374\tBest loss: 0.997374\tAccuracy: 62.67%\n",
      "67\tValidation loss: 1.004486\tBest loss: 0.997374\tAccuracy: 62.67%\n",
      "68\tValidation loss: 1.003288\tBest loss: 0.997374\tAccuracy: 62.67%\n",
      "69\tValidation loss: 1.003048\tBest loss: 0.997374\tAccuracy: 63.33%\n",
      "70\tValidation loss: 1.006796\tBest loss: 0.997374\tAccuracy: 62.67%\n",
      "71\tValidation loss: 1.003610\tBest loss: 0.997374\tAccuracy: 63.33%\n",
      "72\tValidation loss: 1.004019\tBest loss: 0.997374\tAccuracy: 61.33%\n",
      "73\tValidation loss: 0.998439\tBest loss: 0.997374\tAccuracy: 62.00%\n",
      "74\tValidation loss: 1.002624\tBest loss: 0.997374\tAccuracy: 62.67%\n",
      "75\tValidation loss: 0.993077\tBest loss: 0.993077\tAccuracy: 63.33%\n",
      "76\tValidation loss: 1.002977\tBest loss: 0.993077\tAccuracy: 62.67%\n",
      "77\tValidation loss: 0.997339\tBest loss: 0.993077\tAccuracy: 63.33%\n",
      "78\tValidation loss: 1.003634\tBest loss: 0.993077\tAccuracy: 61.33%\n",
      "79\tValidation loss: 1.004686\tBest loss: 0.993077\tAccuracy: 62.67%\n",
      "80\tValidation loss: 1.001130\tBest loss: 0.993077\tAccuracy: 63.33%\n",
      "81\tValidation loss: 0.994202\tBest loss: 0.993077\tAccuracy: 63.33%\n",
      "82\tValidation loss: 1.000315\tBest loss: 0.993077\tAccuracy: 63.33%\n",
      "83\tValidation loss: 0.998215\tBest loss: 0.993077\tAccuracy: 63.33%\n",
      "84\tValidation loss: 1.001026\tBest loss: 0.993077\tAccuracy: 63.33%\n",
      "85\tValidation loss: 0.997090\tBest loss: 0.993077\tAccuracy: 63.33%\n",
      "86\tValidation loss: 0.998991\tBest loss: 0.993077\tAccuracy: 62.67%\n",
      "87\tValidation loss: 0.996299\tBest loss: 0.993077\tAccuracy: 63.33%\n",
      "88\tValidation loss: 0.997501\tBest loss: 0.993077\tAccuracy: 63.33%\n",
      "89\tValidation loss: 0.995899\tBest loss: 0.993077\tAccuracy: 62.67%\n",
      "90\tValidation loss: 0.994480\tBest loss: 0.993077\tAccuracy: 63.33%\n",
      "91\tValidation loss: 0.992918\tBest loss: 0.992918\tAccuracy: 63.33%\n",
      "92\tValidation loss: 0.996333\tBest loss: 0.992918\tAccuracy: 62.67%\n",
      "93\tValidation loss: 0.995975\tBest loss: 0.992918\tAccuracy: 63.33%\n",
      "94\tValidation loss: 0.992923\tBest loss: 0.992918\tAccuracy: 63.33%\n",
      "95\tValidation loss: 0.995152\tBest loss: 0.992918\tAccuracy: 63.33%\n",
      "96\tValidation loss: 0.995405\tBest loss: 0.992918\tAccuracy: 63.33%\n",
      "97\tValidation loss: 0.987243\tBest loss: 0.987243\tAccuracy: 64.00%\n",
      "98\tValidation loss: 0.993903\tBest loss: 0.987243\tAccuracy: 62.67%\n",
      "99\tValidation loss: 0.993843\tBest loss: 0.987243\tAccuracy: 63.33%\n",
      "100\tValidation loss: 0.993105\tBest loss: 0.987243\tAccuracy: 62.67%\n",
      "101\tValidation loss: 0.991695\tBest loss: 0.987243\tAccuracy: 63.33%\n",
      "102\tValidation loss: 0.983825\tBest loss: 0.983825\tAccuracy: 63.33%\n",
      "103\tValidation loss: 0.994330\tBest loss: 0.983825\tAccuracy: 63.33%\n",
      "104\tValidation loss: 0.989133\tBest loss: 0.983825\tAccuracy: 64.00%\n",
      "105\tValidation loss: 0.986579\tBest loss: 0.983825\tAccuracy: 63.33%\n",
      "106\tValidation loss: 0.993653\tBest loss: 0.983825\tAccuracy: 62.67%\n",
      "107\tValidation loss: 0.994730\tBest loss: 0.983825\tAccuracy: 63.33%\n",
      "108\tValidation loss: 0.989402\tBest loss: 0.983825\tAccuracy: 64.00%\n",
      "109\tValidation loss: 0.992066\tBest loss: 0.983825\tAccuracy: 63.33%\n",
      "110\tValidation loss: 0.990766\tBest loss: 0.983825\tAccuracy: 63.33%\n",
      "111\tValidation loss: 0.994172\tBest loss: 0.983825\tAccuracy: 62.67%\n",
      "112\tValidation loss: 0.991444\tBest loss: 0.983825\tAccuracy: 63.33%\n",
      "113\tValidation loss: 0.987783\tBest loss: 0.983825\tAccuracy: 64.00%\n",
      "114\tValidation loss: 0.986716\tBest loss: 0.983825\tAccuracy: 63.33%\n",
      "115\tValidation loss: 0.990349\tBest loss: 0.983825\tAccuracy: 62.67%\n",
      "116\tValidation loss: 0.986582\tBest loss: 0.983825\tAccuracy: 64.00%\n",
      "117\tValidation loss: 0.992177\tBest loss: 0.983825\tAccuracy: 63.33%\n",
      "118\tValidation loss: 0.982751\tBest loss: 0.982751\tAccuracy: 63.33%\n",
      "119\tValidation loss: 0.986655\tBest loss: 0.982751\tAccuracy: 64.00%\n",
      "120\tValidation loss: 0.986350\tBest loss: 0.982751\tAccuracy: 63.33%\n",
      "121\tValidation loss: 0.990556\tBest loss: 0.982751\tAccuracy: 63.33%\n",
      "122\tValidation loss: 0.990022\tBest loss: 0.982751\tAccuracy: 64.00%\n",
      "123\tValidation loss: 0.987283\tBest loss: 0.982751\tAccuracy: 63.33%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\tValidation loss: 0.993649\tBest loss: 0.982751\tAccuracy: 63.33%\n",
      "125\tValidation loss: 0.985647\tBest loss: 0.982751\tAccuracy: 63.33%\n",
      "126\tValidation loss: 0.983785\tBest loss: 0.982751\tAccuracy: 63.33%\n",
      "127\tValidation loss: 0.988552\tBest loss: 0.982751\tAccuracy: 63.33%\n",
      "128\tValidation loss: 0.984974\tBest loss: 0.982751\tAccuracy: 63.33%\n",
      "129\tValidation loss: 0.988550\tBest loss: 0.982751\tAccuracy: 63.33%\n",
      "130\tValidation loss: 0.987274\tBest loss: 0.982751\tAccuracy: 64.00%\n",
      "131\tValidation loss: 0.988010\tBest loss: 0.982751\tAccuracy: 62.00%\n",
      "132\tValidation loss: 0.983320\tBest loss: 0.982751\tAccuracy: 63.33%\n",
      "133\tValidation loss: 0.985608\tBest loss: 0.982751\tAccuracy: 63.33%\n",
      "134\tValidation loss: 0.980552\tBest loss: 0.980552\tAccuracy: 64.00%\n",
      "135\tValidation loss: 0.986996\tBest loss: 0.980552\tAccuracy: 63.33%\n",
      "136\tValidation loss: 0.991633\tBest loss: 0.980552\tAccuracy: 62.00%\n",
      "137\tValidation loss: 0.991004\tBest loss: 0.980552\tAccuracy: 64.00%\n",
      "138\tValidation loss: 0.984321\tBest loss: 0.980552\tAccuracy: 62.00%\n",
      "139\tValidation loss: 0.983197\tBest loss: 0.980552\tAccuracy: 63.33%\n",
      "140\tValidation loss: 0.977042\tBest loss: 0.977042\tAccuracy: 64.67%\n",
      "141\tValidation loss: 0.985450\tBest loss: 0.977042\tAccuracy: 63.33%\n",
      "142\tValidation loss: 0.983142\tBest loss: 0.977042\tAccuracy: 64.00%\n",
      "143\tValidation loss: 0.988008\tBest loss: 0.977042\tAccuracy: 64.00%\n",
      "144\tValidation loss: 0.982821\tBest loss: 0.977042\tAccuracy: 62.67%\n",
      "145\tValidation loss: 0.984945\tBest loss: 0.977042\tAccuracy: 64.00%\n",
      "146\tValidation loss: 0.983474\tBest loss: 0.977042\tAccuracy: 64.00%\n",
      "147\tValidation loss: 0.978850\tBest loss: 0.977042\tAccuracy: 64.67%\n",
      "148\tValidation loss: 0.987341\tBest loss: 0.977042\tAccuracy: 64.00%\n",
      "149\tValidation loss: 0.987304\tBest loss: 0.977042\tAccuracy: 63.33%\n",
      "150\tValidation loss: 0.978644\tBest loss: 0.977042\tAccuracy: 64.67%\n",
      "151\tValidation loss: 0.984138\tBest loss: 0.977042\tAccuracy: 64.00%\n",
      "152\tValidation loss: 0.982977\tBest loss: 0.977042\tAccuracy: 64.00%\n",
      "153\tValidation loss: 0.978362\tBest loss: 0.977042\tAccuracy: 64.67%\n",
      "154\tValidation loss: 0.982949\tBest loss: 0.977042\tAccuracy: 62.67%\n",
      "155\tValidation loss: 0.985073\tBest loss: 0.977042\tAccuracy: 63.33%\n",
      "156\tValidation loss: 0.985089\tBest loss: 0.977042\tAccuracy: 64.67%\n",
      "157\tValidation loss: 0.982585\tBest loss: 0.977042\tAccuracy: 63.33%\n",
      "158\tValidation loss: 0.984604\tBest loss: 0.977042\tAccuracy: 64.00%\n",
      "159\tValidation loss: 0.981444\tBest loss: 0.977042\tAccuracy: 64.67%\n",
      "160\tValidation loss: 0.985480\tBest loss: 0.977042\tAccuracy: 64.67%\n",
      "Early stopping!\n",
      "INFO:tensorflow:Restoring parameters from ./mnistModel_5_to_9_four_frozen\n",
      "Final test accuracy: 61.72%\n"
     ]
    }
   ],
   "source": [
    "print('Task 4 start')\n",
    "time.sleep(1)\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "n_outputs = 5\n",
    "learning_rate = 0.01\n",
    "\n",
    "restore_saver = tf.train.import_meta_graph(\"./model.meta\")\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "\n",
    "hidden4_out = tf.get_default_graph().get_tensor_by_name(\"hidden4_out:0\")\n",
    "logits = tf.layers.dense(hidden4_out, n_outputs, kernel_initializer=he_init, name=\"new_logits\")\n",
    "Y_proba = tf.nn.softmax(logits)\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"new_logits\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam2\")\n",
    "training_op = optimizer.minimize(loss, var_list=output_layer_vars)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "four_frozen_saver = tf.train.Saver()\n",
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./model\")\n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train) // batch_size):\n",
    "            X_batch, y_batch = X_train[rnd_indices], y_train[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid, y: y_valid})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = four_frozen_saver.save(sess, \"./mnistModel_5_to_9_four_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    four_frozen_saver.restore(sess, \"./mnistModel_5_to_9_four_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can't achieve higher precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Now unfreeze the top two hidden layers and continue training: can you get the model to perform even better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 5 start\n",
      "INFO:tensorflow:Restoring parameters from ./mnistModel_5_to_9_four_frozen\n",
      "0\tValidation loss: 0.984967\tBest loss: 0.984967\tAccuracy: 62.67%\n",
      "1\tValidation loss: 0.984831\tBest loss: 0.984831\tAccuracy: 64.00%\n",
      "2\tValidation loss: 0.972830\tBest loss: 0.972830\tAccuracy: 64.67%\n",
      "3\tValidation loss: 0.971631\tBest loss: 0.971631\tAccuracy: 64.67%\n",
      "4\tValidation loss: 0.973418\tBest loss: 0.971631\tAccuracy: 64.67%\n",
      "5\tValidation loss: 0.979836\tBest loss: 0.971631\tAccuracy: 63.33%\n",
      "6\tValidation loss: 0.967368\tBest loss: 0.967368\tAccuracy: 66.00%\n",
      "7\tValidation loss: 0.963179\tBest loss: 0.963179\tAccuracy: 66.67%\n",
      "8\tValidation loss: 0.966520\tBest loss: 0.963179\tAccuracy: 66.67%\n",
      "9\tValidation loss: 0.962242\tBest loss: 0.962242\tAccuracy: 66.00%\n",
      "10\tValidation loss: 0.959144\tBest loss: 0.959144\tAccuracy: 66.00%\n",
      "11\tValidation loss: 0.961056\tBest loss: 0.959144\tAccuracy: 66.67%\n",
      "12\tValidation loss: 0.957902\tBest loss: 0.957902\tAccuracy: 67.33%\n",
      "13\tValidation loss: 0.961002\tBest loss: 0.957902\tAccuracy: 65.33%\n",
      "14\tValidation loss: 0.963510\tBest loss: 0.957902\tAccuracy: 67.33%\n",
      "15\tValidation loss: 0.955678\tBest loss: 0.955678\tAccuracy: 66.00%\n",
      "16\tValidation loss: 0.955110\tBest loss: 0.955110\tAccuracy: 68.00%\n",
      "17\tValidation loss: 0.949553\tBest loss: 0.949553\tAccuracy: 66.00%\n",
      "18\tValidation loss: 0.944125\tBest loss: 0.944125\tAccuracy: 66.00%\n",
      "19\tValidation loss: 0.947438\tBest loss: 0.944125\tAccuracy: 67.33%\n",
      "20\tValidation loss: 0.941920\tBest loss: 0.941920\tAccuracy: 66.67%\n",
      "21\tValidation loss: 0.949713\tBest loss: 0.941920\tAccuracy: 67.33%\n",
      "22\tValidation loss: 0.945497\tBest loss: 0.941920\tAccuracy: 66.67%\n",
      "23\tValidation loss: 0.949771\tBest loss: 0.941920\tAccuracy: 68.00%\n",
      "24\tValidation loss: 0.943839\tBest loss: 0.941920\tAccuracy: 69.33%\n",
      "25\tValidation loss: 0.944404\tBest loss: 0.941920\tAccuracy: 68.67%\n",
      "26\tValidation loss: 0.949937\tBest loss: 0.941920\tAccuracy: 67.33%\n",
      "27\tValidation loss: 0.946439\tBest loss: 0.941920\tAccuracy: 67.33%\n",
      "28\tValidation loss: 0.944772\tBest loss: 0.941920\tAccuracy: 68.00%\n",
      "29\tValidation loss: 0.933233\tBest loss: 0.933233\tAccuracy: 69.33%\n",
      "30\tValidation loss: 0.942187\tBest loss: 0.933233\tAccuracy: 68.00%\n",
      "31\tValidation loss: 0.936278\tBest loss: 0.933233\tAccuracy: 69.33%\n",
      "32\tValidation loss: 0.943660\tBest loss: 0.933233\tAccuracy: 70.00%\n",
      "33\tValidation loss: 0.941256\tBest loss: 0.933233\tAccuracy: 70.00%\n",
      "34\tValidation loss: 0.937459\tBest loss: 0.933233\tAccuracy: 70.67%\n",
      "35\tValidation loss: 0.946878\tBest loss: 0.933233\tAccuracy: 70.67%\n",
      "36\tValidation loss: 0.947144\tBest loss: 0.933233\tAccuracy: 71.33%\n",
      "37\tValidation loss: 0.940068\tBest loss: 0.933233\tAccuracy: 70.67%\n",
      "38\tValidation loss: 0.945990\tBest loss: 0.933233\tAccuracy: 70.00%\n",
      "39\tValidation loss: 0.941300\tBest loss: 0.933233\tAccuracy: 70.67%\n",
      "40\tValidation loss: 0.952511\tBest loss: 0.933233\tAccuracy: 70.67%\n",
      "41\tValidation loss: 0.941583\tBest loss: 0.933233\tAccuracy: 70.67%\n",
      "42\tValidation loss: 0.951919\tBest loss: 0.933233\tAccuracy: 69.33%\n",
      "43\tValidation loss: 0.938765\tBest loss: 0.933233\tAccuracy: 70.67%\n",
      "44\tValidation loss: 0.941657\tBest loss: 0.933233\tAccuracy: 71.33%\n",
      "45\tValidation loss: 0.949913\tBest loss: 0.933233\tAccuracy: 70.67%\n",
      "46\tValidation loss: 0.944017\tBest loss: 0.933233\tAccuracy: 70.67%\n",
      "47\tValidation loss: 0.948445\tBest loss: 0.933233\tAccuracy: 72.00%\n",
      "48\tValidation loss: 0.938016\tBest loss: 0.933233\tAccuracy: 69.33%\n",
      "49\tValidation loss: 0.951530\tBest loss: 0.933233\tAccuracy: 70.67%\n",
      "Early stopping!\n",
      "INFO:tensorflow:Restoring parameters from ./mnistModel_5_to_9_two_frozen\n",
      "Final test accuracy: 63.51%\n",
      "INFO:tensorflow:Restoring parameters from ./mnistModel_5_to_9_two_frozen\n",
      "0\tValidation loss: 0.827291\tBest loss: 0.827291\tAccuracy: 73.33%\n",
      "1\tValidation loss: 0.761120\tBest loss: 0.761120\tAccuracy: 76.67%\n",
      "2\tValidation loss: 0.702915\tBest loss: 0.702915\tAccuracy: 78.00%\n",
      "3\tValidation loss: 0.719664\tBest loss: 0.702915\tAccuracy: 77.33%\n",
      "4\tValidation loss: 0.683127\tBest loss: 0.683127\tAccuracy: 79.33%\n",
      "5\tValidation loss: 0.676590\tBest loss: 0.676590\tAccuracy: 80.67%\n",
      "6\tValidation loss: 0.687430\tBest loss: 0.676590\tAccuracy: 82.67%\n",
      "7\tValidation loss: 0.730717\tBest loss: 0.676590\tAccuracy: 82.00%\n",
      "8\tValidation loss: 0.735824\tBest loss: 0.676590\tAccuracy: 81.33%\n",
      "9\tValidation loss: 0.757953\tBest loss: 0.676590\tAccuracy: 81.33%\n",
      "10\tValidation loss: 0.787331\tBest loss: 0.676590\tAccuracy: 82.67%\n",
      "11\tValidation loss: 0.821911\tBest loss: 0.676590\tAccuracy: 82.67%\n",
      "12\tValidation loss: 0.844614\tBest loss: 0.676590\tAccuracy: 84.00%\n",
      "13\tValidation loss: 0.880345\tBest loss: 0.676590\tAccuracy: 83.33%\n",
      "14\tValidation loss: 0.944105\tBest loss: 0.676590\tAccuracy: 82.67%\n",
      "15\tValidation loss: 0.939098\tBest loss: 0.676590\tAccuracy: 82.00%\n",
      "16\tValidation loss: 0.979469\tBest loss: 0.676590\tAccuracy: 83.33%\n",
      "17\tValidation loss: 0.997149\tBest loss: 0.676590\tAccuracy: 84.00%\n",
      "18\tValidation loss: 1.011993\tBest loss: 0.676590\tAccuracy: 82.67%\n",
      "19\tValidation loss: 1.039711\tBest loss: 0.676590\tAccuracy: 83.33%\n",
      "20\tValidation loss: 1.074635\tBest loss: 0.676590\tAccuracy: 82.67%\n",
      "21\tValidation loss: 1.104595\tBest loss: 0.676590\tAccuracy: 82.67%\n",
      "22\tValidation loss: 1.088879\tBest loss: 0.676590\tAccuracy: 83.33%\n",
      "23\tValidation loss: 1.097202\tBest loss: 0.676590\tAccuracy: 83.33%\n",
      "24\tValidation loss: 1.121091\tBest loss: 0.676590\tAccuracy: 83.33%\n",
      "25\tValidation loss: 1.107674\tBest loss: 0.676590\tAccuracy: 83.33%\n",
      "Early stopping!\n",
      "INFO:tensorflow:Restoring parameters from ./mnistModel_5_to_9_no_frozen\n",
      "Final test accuracy: 79.74%\n",
      "0\tValidation loss: 0.803556\tBest loss: 0.803556\tAccuracy: 71.33%\n",
      "1\tValidation loss: 0.966740\tBest loss: 0.803556\tAccuracy: 85.33%\n",
      "2\tValidation loss: 1.158965\tBest loss: 0.803556\tAccuracy: 78.00%\n",
      "3\tValidation loss: 0.615960\tBest loss: 0.615960\tAccuracy: 88.00%\n",
      "4\tValidation loss: 0.612607\tBest loss: 0.612607\tAccuracy: 92.00%\n",
      "5\tValidation loss: 0.686598\tBest loss: 0.612607\tAccuracy: 89.33%\n",
      "6\tValidation loss: 0.804999\tBest loss: 0.612607\tAccuracy: 89.33%\n",
      "7\tValidation loss: 0.749549\tBest loss: 0.612607\tAccuracy: 88.67%\n",
      "8\tValidation loss: 0.790770\tBest loss: 0.612607\tAccuracy: 87.33%\n",
      "9\tValidation loss: 0.637714\tBest loss: 0.612607\tAccuracy: 94.00%\n",
      "10\tValidation loss: 0.758184\tBest loss: 0.612607\tAccuracy: 91.33%\n",
      "11\tValidation loss: 1.007170\tBest loss: 0.612607\tAccuracy: 89.33%\n",
      "12\tValidation loss: 0.777174\tBest loss: 0.612607\tAccuracy: 91.33%\n",
      "13\tValidation loss: 1.452966\tBest loss: 0.612607\tAccuracy: 89.33%\n",
      "14\tValidation loss: 1.016635\tBest loss: 0.612607\tAccuracy: 91.33%\n",
      "15\tValidation loss: 1.285286\tBest loss: 0.612607\tAccuracy: 92.67%\n",
      "16\tValidation loss: 1.365195\tBest loss: 0.612607\tAccuracy: 88.67%\n",
      "17\tValidation loss: 0.899284\tBest loss: 0.612607\tAccuracy: 91.33%\n",
      "18\tValidation loss: 2.111645\tBest loss: 0.612607\tAccuracy: 91.33%\n",
      "19\tValidation loss: 0.756195\tBest loss: 0.612607\tAccuracy: 86.00%\n",
      "20\tValidation loss: 2.687987\tBest loss: 0.612607\tAccuracy: 86.67%\n",
      "21\tValidation loss: 1.081055\tBest loss: 0.612607\tAccuracy: 86.00%\n",
      "22\tValidation loss: 1.723082\tBest loss: 0.612607\tAccuracy: 88.00%\n",
      "23\tValidation loss: 2.454844\tBest loss: 0.612607\tAccuracy: 89.33%\n",
      "24\tValidation loss: 2.364795\tBest loss: 0.612607\tAccuracy: 92.00%\n",
      "25\tValidation loss: 1.960627\tBest loss: 0.612607\tAccuracy: 86.67%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8996091339230611"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Task 5 start')\n",
    "time.sleep(1)\n",
    "\n",
    "learning_rate = 0.01\n",
    "unfrozen_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"hidden[34]|new_logits\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam23\")\n",
    "training_op = optimizer.minimize(loss, var_list=unfrozen_vars)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "two_frozen_saver = tf.train.Saver()\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    four_frozen_saver.restore(sess, \"./mnistModel_5_to_9_four_frozen\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train) // batch_size):\n",
    "            X_batch, y_batch = X_train[rnd_indices], y_train[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid, y: y_valid})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = two_frozen_saver.save(sess, \"./mnistModel_5_to_9_two_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    two_frozen_saver.restore(sess, \"./mnistModel_5_to_9_two_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam24\")\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "no_frozen_saver = tf.train.Saver()\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    two_frozen_saver.restore(sess, \"./mnistModel_5_to_9_two_frozen\")\n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train) // batch_size):\n",
    "            X_batch, y_batch = X_train[rnd_indices], y_train[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid, y: y_valid})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = no_frozen_saver.save(sess, \"./mnistModel_5_to_9_no_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    no_frozen_saver.restore(sess, \"./mnistModel_5_to_9_no_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))\n",
    "\n",
    "dnn_clf_5_to_9 = DNNClassifier(n_hidden_layers=4, random_state=42)\n",
    "dnn_clf_5_to_9.fit(X_train, y_train, n_epochs=1000, X_valid=X_valid, y_valid=y_valid)\n",
    "y_pred = dnn_clf_5_to_9.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So unfreezing the top two hidden layers dramastically improves the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
